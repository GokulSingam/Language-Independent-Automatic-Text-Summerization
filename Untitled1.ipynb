{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cec7f35",
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "import csv\n",
    "import pandas as pd\n",
    "import random\n",
    "import numpy as np\n",
    "import math\n",
    "import nltk\n",
    "from gensim import corpora\n",
    "from nltk.tokenize import sent_tokenize,word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "import gensim\n",
    "LDA= gensim.models.ldamodel.LdaModel\n",
    "nlp = spacy.load('en_core_web_md', disable=['parser', 'ner'])\n",
    "stop_words = stopwords.words('english')\n",
    "#getting data\n",
    "articles= pd.read_csv(\"c:\\\\Gokul\\\\miniproject\\\\dataset\\\\cnn_dailymail\\\\test.csv\")\n",
    "summary=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "deee0cc2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#population initalisation\n",
    "def initial_population(pop_len):\n",
    "    initial_pop=[]\n",
    "    for i in range(pop_len):\n",
    "        z=[]\n",
    "        for j in range(pop_len):\n",
    "            z.append(random.randint(0,1))\n",
    "        initial_pop.append(z)\n",
    "    return initial_pop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dad6a729",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def calculate_fitness(population):\n",
    "    fitness=[]\n",
    "    a=[]\n",
    "    b=[]\n",
    "    length=0\n",
    "    length=len(population)\n",
    "    for k in range(length):\n",
    "        for i in range(length):\n",
    "            h=0\n",
    "            for j in range(length):\n",
    "                if population[k][i]!=population[k][j]:\n",
    "                    h=h+1\n",
    "        a.append((1/(1+math.sqrt(h))))\n",
    "    for t in range(length):\n",
    "        distance=0\n",
    "        for k in range(length):\n",
    "            h=0\n",
    "            for j in range(length):\n",
    "                if population[t][j]!=population[k][j]:\n",
    "                    h=h+1\n",
    "            distance=distance+(1+(1+math.sqrt(h)))\n",
    "        b.append(distance/length)\n",
    "    for i in range(length):\n",
    "        h=b[i]-a[i]\n",
    "        maximum=0\n",
    "        if b[i]>a[i]:\n",
    "            maximum=b[i]\n",
    "        else:\n",
    "            maximum=a[i]\n",
    "        if h<0:\n",
    "            h=-h\n",
    "        fitness.append(h/maximum)\n",
    "#     print(\"cluster \",\"\\t\"*5 ,\"fitness\")\n",
    "#     for i in range(len(fitness)):\n",
    "#         print(population[i],fitness[i])\n",
    "    return fitness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37156920",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def get_probability(fitness):\n",
    "    total_fit = sum(fitness)\n",
    "    relative_fitness = [f/total_fit for f in fitness]\n",
    "    probabilities = [sum(relative_fitness[:i+1]) \n",
    "                     for i in range(len(relative_fitness))]\n",
    "    p=np.array(probabilities)\n",
    "#     print(p)\n",
    "    return p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aaccd3c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def selection(population, probabilities, number):\n",
    "    chosen = []\n",
    "    z=max(probabilities)\n",
    "    length=len(population)\n",
    "    \n",
    "    while len(chosen)!=number:\n",
    "        r = random.uniform(0,z)\n",
    "        for (i, individual) in enumerate(population):\n",
    "            if i==length-1 and r<probabilities[i]:\n",
    "                chosen.append(list(individual))\n",
    "            elif r>probabilities[i] and r <= probabilities[i+1]:\n",
    "                chosen.append(list(individual))\n",
    "                break\n",
    "    return chosen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "766d7132",
   "metadata": {},
   "outputs": [],
   "source": [
    "def crossover(parents):\n",
    "    length = len(parents[0])\n",
    "    children = [] \n",
    "    if random.random()<=0.7 :\n",
    "        r1 = random.randrange(0, length)\n",
    "        r2 = random.randrange(0, length)\n",
    "      \n",
    "        if r1 < r2:\n",
    "            children.append(parents[0][:r1] + parents[1][r1:r2] + parents[0][r2:])\n",
    "            children.append(parents[1][:r1] + parents[0][r1:r2] + parents[1][r2:])\n",
    "        else:\n",
    "            children.append(parents[0][:r2] + parents[1][r2:r1] + parents[0][r1:])\n",
    "            children.append(parents[1][:r2] + parents[0][r2:r1] + parents[1][r1:])\n",
    "    else:\n",
    "        children.append(parents[0])\n",
    "        children.append(parents[1])\n",
    "    return children"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "065cb26f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def bitflip(bit): # used in mutation \n",
    "    if bit == 0:\n",
    "        bit=1\n",
    "    elif bit==1:\n",
    "        bit=0\n",
    "    return bit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99a2dcef",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mutation(individual):\n",
    " # bitwise mutation with probability PROB_MUTATION\n",
    "    for i in range(len(individual)):\n",
    "        if random.random()< 0.3:\n",
    "            individual[i]=bitflip(individual[i])\n",
    "    return(individual)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ae43e11",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sort_new_pop(population,length):\n",
    "    fitness=calculate_fitness(population)\n",
    "    temp_fit=fitness.copy()\n",
    "    fitness.sort()\n",
    "    fitness.reverse()\n",
    "    new_pop=[]\n",
    "    for i in range(len(fitness)):\n",
    "        for j in range(len(fitness)):\n",
    "            if fitness[i]==temp_fit[j]:\n",
    "                new_pop.append(population[j])\n",
    "                break\n",
    "# #     print(\"cluster \",\"\\t\"*5 ,\"fitness\")\n",
    "#     for i in range(length):\n",
    "#         print(population[i],fitness[i])\n",
    "    return new_pop[:length]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc6bd6ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "def genetic_algorithm(population,n):\n",
    "    length=len(population)\n",
    "    if n==0:\n",
    "#         print(calculate_fitness(population))\n",
    "        return population\n",
    "    else:\n",
    "        new_pop=[]\n",
    "        fitness=calculate_fitness(population) \n",
    "        probabilities=get_probability(fitness)\n",
    "        rang=int(len(population)/2)\n",
    "        for i in range(rang):\n",
    "            parents=selection(population, probabilities, 2)\n",
    "            children=crossover(parents)\n",
    "            for i in children:\n",
    "                new_pop.append(mutation(i))\n",
    "        if len(population)!=len(new_pop):\n",
    "            parents=selection(population, probabilities, 2)\n",
    "            children=crossover(parents)\n",
    "            for i in children:\n",
    "                new_pop.append(mutation(i))\n",
    "            new_pop=new_pop[:(len(new_pop)-1)]\n",
    "        popu=sort_new_pop(new_pop,length)\n",
    "        return genetic_algorithm(popu,n-1)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb68377a",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def form_clusters(length): \n",
    "    pop=initial_population(length)\n",
    "    z=genetic_algorithm(pop,50)\n",
    "    length=len(z)\n",
    "    cluster_indexes=set()\n",
    "    sentence_indexes=[]\n",
    "    h=0\n",
    "    while h<=length:\n",
    "        for j in range(length):\n",
    "            for k in range(length):\n",
    "                if z[k][j]==1:\n",
    "                    cluster_indexes.add(k)\n",
    "                    h=h+1\n",
    "                    break                    \n",
    "    clusters=[]\n",
    "    for i in cluster_indexes:\n",
    "        clusters.append(z[i])\n",
    "#     for i in clusters:\n",
    "#         print(i)\n",
    "    return clusters\n",
    "# r=form_clusters(len(sent_tokenize(articles['article'][0])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7defbb5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_clusters(sent_tokens):\n",
    "    length=len(sent_tokens)\n",
    "    clusters=form_clusters(length)\n",
    "    documents=[]\n",
    "    for i in range(len(clusters)):\n",
    "        sent=\" \"\n",
    "        k=0\n",
    "        for j in clusters[i]:\n",
    "            if j==1:\n",
    "                sent=sent+\" \"+sent_tokens[k]\n",
    "            k=k+1\n",
    "        documents.append(sent)\n",
    "    for i in clusters:\n",
    "        print(i)\n",
    "    return clusters,documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12882445",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text(text):\n",
    "    sent_tokens=sent_tokenize(text)\n",
    "    s=\" \"\n",
    "    for sentence in sent_tokens:\n",
    "        sentence = sentence.lower()\n",
    "        sentence = sentence.replace(r\"[^a-zA-Z0-9]+\",\" \")\n",
    "        sentence = sentence.replace(r\"([^\\w])\",\" \") \n",
    "        sentence = sentence.replace(r\"\\b\\d+\\b\", \" \")\n",
    "        sentence = sentence.replace(r\"\\s+|\\r|\\n\", \" \")\n",
    "        sentence = sentence.replace(r\"^\\s+|\\s$\", \" \")\n",
    "        punc = '''!()-[]{};:\"\\,'<>./?@#$%^&*_~'''\n",
    "        for char in sentence:\n",
    "            if char in punc:\n",
    "                sentence = sentence.replace(char, \"\")\n",
    "        wordtokens=word_tokenize(sentence)\n",
    "        tokens_without_sw = [word for word in wordtokens if not word in stopwords.words()]\n",
    "        for word in wordtokens:\n",
    "            if not word in stopwords.words():\n",
    "                s=s+\" \"+word\n",
    "        s=s+\".\"\n",
    "#     print(s)\n",
    "    return s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f466b5b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_stopwords(text):\n",
    "    sent_tokens=sent_tokenize(text)\n",
    "    s=\" \"\n",
    "    for sentence in sent_tokens:\n",
    "        \n",
    "        wordtokens=word_tokenize(sentence)\n",
    "        tokens_without_sw = [word for word in wordtokens if not word in stopwords.words()]\n",
    "        for word in wordtokens:\n",
    "            if not word in stopwords.words():\n",
    "                s=s+\" \"+word\n",
    "        s=s+\".\"\n",
    "    return s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53cf4b77",
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load('en_core_web_md', disable=['parser', 'ner'])\n",
    "\n",
    "def lemmatization(texts,allowed_postags=['NOUN', 'ADJ']): \n",
    "    output = []\n",
    "    sentwise_tokens=[]\n",
    "    sent_tokens=sent_tokenize(texts)\n",
    "    for sent in sent_tokens:\n",
    "        doc = nlp(sent)\n",
    "        sent_tok=[]\n",
    "        \n",
    "        for token in doc :\n",
    "            \n",
    "            if token.pos_ in allowed_postags:\n",
    "                output.append(token.lemma_)\n",
    "                sent_tok.append(token.lemma_)\n",
    "        sentwise_tokens.append(sent_tok)\n",
    "    \n",
    "    return output,sentwise_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd260048",
   "metadata": {},
   "outputs": [],
   "source": [
    "def doc_term(tokenized_documents,dictionary):\n",
    "    doc_term_matrix=[]\n",
    "    for i in tokenized_documents:\n",
    "        doc_term_matrix.append(dictionary.doc2bow(i))\n",
    "    return doc_term_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90a90d0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Sort_Tuple(tup): \n",
    "    # getting length of list of tuples\n",
    "    lst = len(tup) \n",
    "    for i in range(0, lst): \n",
    "        for j in range(0, lst-i-1): \n",
    "            if (tup[j][1] < tup[j + 1][1]): \n",
    "                temp = tup[j] \n",
    "                tup[j]= tup[j + 1] \n",
    "                tup[j + 1]= temp \n",
    "    return tup "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3084c58b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def con_to_doc(tokens):\n",
    "    doc=\" \"\n",
    "    for i in tokens:\n",
    "        doc=doc+' '+i\n",
    "    return doc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba35f4e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_document(sent_tokens):\n",
    "    length=len(sent_tokens)\n",
    "    h=int(length/3)\n",
    "    docs=[]\n",
    "    doc1=con_to_doc(sent_tokens[:h])\n",
    "    doc2=con_to_doc(sent_tokens[h:h*2])\n",
    "    doc3=con_to_doc(sent_tokens[h*2:length])\n",
    "    docs.append(doc1)\n",
    "    docs.append(doc2)\n",
    "    docs.append(doc3)\n",
    "    return docs\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c23a3ebe",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_clean_text(documents):\n",
    "    x=[]\n",
    "    for doc in documents:\n",
    "        i=clean_text(doc)\n",
    "        x.append(i)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "762c1e19",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenized_docs(docs):\n",
    "    a=[]\n",
    "    b=[]\n",
    "    for t in docs:\n",
    "        g,h=lemmatization(t)\n",
    "        a.append(g)\n",
    "        b.append(h)\n",
    "    return a,b\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25dbc861",
   "metadata": {},
   "outputs": [],
   "source": [
    "def form_tuple(cluster,sent_wise_token,words,values,sent_tokens):\n",
    "    prob_list=[]\n",
    "    h=0\n",
    "    for  i in sent_wise_token:\n",
    "        prob=0\n",
    "        for word in i:\n",
    "            if word in words[0]:\n",
    "                ind=words[0].index(word)\n",
    "                prob=prob+values[0][ind]\n",
    "            if word in words[1]:\n",
    "                ind=words[1].index(word)\n",
    "                prob=prob+values[1][ind]\n",
    "            if word in words[2]:\n",
    "                ind=words[2].index(word)\n",
    "                prob=prob+values[2][ind]\n",
    "        prob_list.append(prob)\n",
    "#     print(prob_list)\n",
    "    j=0\n",
    "    t=[]\n",
    "    k=0\n",
    "    for i in range(len(cluster)):\n",
    "        if cluster[i]==1:\n",
    "            k=k+1\n",
    "            t.append((sent_tokens[i],prob_list[j]))\n",
    "            j=j+1\n",
    "    return t     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ef3f8e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def form_sentence_tuples(clusters,sent_wise_tokens,words,values,sent_tokens):\n",
    "    listt=[]\n",
    "    for i in range(len(clusters)):\n",
    "        listt.append(form_tuple(clusters[i],sent_wise_tokens[i],words,values,sent_tokens))\n",
    "    return listt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1ca0058",
   "metadata": {},
   "outputs": [],
   "source": [
    "from  math import ceil \n",
    "def form_summary(clusters):\n",
    "    text=set()\n",
    "    k=[]\n",
    "    for i in clusters:\n",
    "        k.append(Sort_Tuple(i))\n",
    "    h=[]\n",
    "    for j in k:\n",
    "        length=len(j)\n",
    "        print(length)\n",
    "        m=0\n",
    "        while m!=length:\n",
    "            if j[m][0] in h:\n",
    "                m=m+1\n",
    "                continue\n",
    "            else:\n",
    "                h.append(j[m][0])\n",
    "                m=m+1\n",
    "                break\n",
    "          \n",
    "    summary=\" \"\n",
    "    print(h)\n",
    "    for i in range(ceil(len(h))):\n",
    "        summary=summary+\" \"+h[i]\n",
    "    return summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "946cabae",
   "metadata": {},
   "outputs": [],
   "source": [
    "def summerize_text(text):\n",
    "    texts=clean_text(text)\n",
    "    sent_tokens=sent_tokenize(texts)\n",
    "    documents=split_document(sent_tokens)\n",
    "    clusters,clustered_documents=get_clusters(sent_tokens)\n",
    "    clust_docs,sent_wise_tokens=tokenized_docs(clustered_documents)\n",
    "    tokenized_documents=[]\n",
    "    for t in documents:\n",
    "        g,h=lemmatization(t)\n",
    "        tokenized_documents.append(g)\n",
    "    dictionary = corpora.Dictionary(tokenized_documents)\n",
    "    doc_term_matrix = doc_term(tokenized_documents,dictionary)\n",
    "    lda_model = LDA(corpus=doc_term_matrix, id2word=dictionary, num_topics=3\n",
    "                ,\n",
    "                chunksize=20, passes=10,alpha=1,eta=0.001,iterations=10,per_word_topics=True,update_every=1)\n",
    "    ttext=lda_model.print_topics(num_words=10)\n",
    "    \n",
    "    words=[]\n",
    "    values=[]\n",
    "    for k in range(len(ttext)):\n",
    "        keys=[]\n",
    "        value=[]\n",
    "        h=ttext[k][1].split('+')\n",
    "        for i in range(len(h)):\n",
    "            v,k=h[i].split('*')\n",
    "            if i==9:\n",
    "                keys.append(str(k[1:len(k)-1]))\n",
    "            else:\n",
    "                 keys.append(str(k[1:len(k)-2]))\n",
    "            value.append(float(v))\n",
    "        words.append(keys)\n",
    "        values.append(value)\n",
    "    \n",
    "#     for i in range(3):\n",
    "#         print(\"word\",\"probability\",\"  \",\"topic\",i+1)\n",
    "#         for j in range(len(words[i])):\n",
    "#             print(words[i][j],\"     \",values[i][j])\n",
    "    prob_sentences_clust=form_sentence_tuples(clusters,sent_wise_tokens,words,values,sent_tokens)\n",
    "    summary=form_summary(prob_sentences_clust)    \n",
    "    return summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4103ce89",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "avg_rouge1=0\n",
    "rouge11=0\n",
    "rouge21=0\n",
    "rougeL=0\n",
    "l=len(articles['article'])\n",
    "from rouge import Rouge\n",
    "rouge=Rouge()\n",
    "list1=pd.read_csv(\"c:\\\\Gokul\\\\miniproject\\\\goldsummary.csv\")\n",
    "# list2=pd.read_csv(\"c:\\\\Gokul\\\\miniproject\\\\summary.csv\")\n",
    "for i in range(0,l):\n",
    "    print(i)\n",
    "    r1,p1,f1=0,0,0\n",
    "    r2,p2,f2=0,0,0\n",
    "    rl,pl,fl=0,0,0\n",
    "    l1=list1['goldsumm'][i]\n",
    "    z=summerize_text(articles['article'][i])\n",
    "    summary.append(z)\n",
    "    print(z)\n",
    "#     l2=list2['summary'][i]\n",
    "    scores = rouge.get_scores(z,l1)\n",
    "#     print(scores)\n",
    "    r1=r1+scores[0]['rouge-1']['r']\n",
    "    p1=p1+scores[0]['rouge-1']['p']\n",
    "    f1=f1+scores[0]['rouge-1']['f'] \n",
    "    r2=r2+scores[0]['rouge-2']['r']\n",
    "    p2=p2+scores[0]['rouge-2']['p']\n",
    "    f2=f2+scores[0]['rouge-2']['f'] \n",
    "    rl=rl+scores[0]['rouge-l']['r']\n",
    "    pl=pl+scores[0]['rouge-l']['p']\n",
    "    fl=fl+scores[0]['rouge-l']['f'] \n",
    "    rouge1=(r1+p1+f1)/3\n",
    "    rouge2=(r2+p2+f2)/3\n",
    "    rougel=(rl+pl+fl)/3\n",
    "    print(\"rouge-1 :\",rouge1*100)\n",
    "    print(\"rouge-2 :\",rouge2*100)\n",
    "    print(\"rouge-L :\",rougel*100)\n",
    "    rouge11=rouge11+rouge1\n",
    "    rouge21=rouge21+rouge2\n",
    "    rougeL=rougeL+rougel\n",
    "    avg_rouge=((rouge1+rouge2+rougel)/3)\n",
    "    avg_rouge1=avg_rouge1+avg_rouge\n",
    "    print(\"avg_rouge\",avg_rouge*100)\n",
    "print(\"rouge-1 :\",rouge11*100)\n",
    "print(\"rouge-2 :\",rouge21*100)\n",
    "print(\"rouge-L :\",rougeL*100)   \n",
    "print(\"avg_rouge\",avg_rouge1*100)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db93bb89",
   "metadata": {},
   "outputs": [],
   "source": [
    "from csv import writer\n",
    "k=zip(summary)\n",
    "with open('c:\\\\Gokul\\\\miniproject\\\\summary3.csv','w',encoding='utf-8',newline='') as writefile:\n",
    "    csv_w=writer(writefile)\n",
    "    for i in k:\n",
    "        csv_w.writerow(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae6bdaa5",
   "metadata": {},
   "outputs": [],
   "source": [
    "k=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4db0e55c",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in articles['highlights']:\n",
    "    z=clean_text(i)\n",
    "    k.append(z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f41ecc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "h=zip(k)\n",
    "with open('c:\\\\Gokul\\\\miniproject\\\\goldsummary.csv','w',encoding='utf-8',newline='') as writefile:\n",
    "    csv_w=writer(writefile)\n",
    "    for i in h:\n",
    "        csv_w.writerow(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f729b12",
   "metadata": {},
   "outputs": [],
   "source": [
    "from rouge import Rouge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b455742",
   "metadata": {},
   "outputs": [],
   "source": [
    "rouge=Rouge()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa693050",
   "metadata": {},
   "outputs": [],
   "source": [
    "list1=pd.read_csv(\"c:\\\\Gokul\\\\miniproject\\\\goldsummary.csv\")\n",
    "list2=pd.read_csv(\"c:\\\\Gokul\\\\miniproject\\\\summary.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52c65f0a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "l=len(list1['goldsumm'])\n",
    "r1,p1,f1=0,0,0\n",
    "r2,p2,f2=0,0,0\n",
    "rl,pl,fl=0,0,0\n",
    "for i in range(0,l,1):\n",
    "    l1=list1['goldsumm'][i]\n",
    "    l2=list2['summary'][i]\n",
    "    scores = rouge.get_scores(l2,l1)\n",
    "#     print(scores)\n",
    "#     print(scores)\n",
    "    r1=r1+scores[0]['rouge-1']['r']\n",
    "    p1=p1+scores[0]['rouge-1']['p']\n",
    "    f1=f1+scores[0]['rouge-1']['f'] \n",
    "    r2=r2+scores[0]['rouge-2']['r']\n",
    "    p2=p2+scores[0]['rouge-2']['p']\n",
    "    f2=f2+scores[0]['rouge-2']['f'] \n",
    "    rl=rl+scores[0]['rouge-l']['r']\n",
    "    pl=pl+scores[0]['rouge-l']['p']\n",
    "    fl=fl+scores[0]['rouge-l']['f'] \n",
    "rouge1=((r1+p1+f1)/l)/3\n",
    "rouge2=((r2+p2+f2)/l)/3\n",
    "rougel=((rl+pl+fl)/l)/3\n",
    "print(\"rouge-1 :\",rouge1*100)\n",
    "print(\"rouge-2 :\",rouge2*100)\n",
    "print(\"rouge-L :\",rougel*100)\n",
    "avg_rouge=((rouge1+rouge2+rougel)/3)\n",
    "print(\"avg_rouge\",avg_rouge*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c531c6f0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9662c78a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "671cba72",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2ce474b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
